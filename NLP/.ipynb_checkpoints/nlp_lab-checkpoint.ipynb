{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec33e0a1-c06b-42d9-a4a1-537301f62d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import zeros, array\n",
    "from functools import lru_cache\n",
    "from math import log\n",
    "from tqdm import tqdm\n",
    "\n",
    "from random import randint as rint\n",
    "from random import seed\n",
    "seed(42)\n",
    "\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cba197f-fa68-46f2-8668-b178d727f707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lemma\n",
      "0            а\n",
      "1           аа\n",
      "2          а-а\n",
      "3          ааа\n",
      "4        а-а-а\n",
      "...        ...\n",
      "51728  ящерица\n",
      "51729   ящерка\n",
      "51730     ящик\n",
      "51731   ящичек\n",
      "51732     ящур\n",
      "\n",
      "[51733 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "lemma_dict = pd.read_csv('C:\\\\Python programs\\\\ru_dict_lemma.csv')\n",
    "print(lemma_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bae3ce3a-ee4d-4f35-8d8c-9497b10edf3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               form          lemma  id_sen\n",
      "0                 «              «     0.0\n",
      "1              Если           если     0.0\n",
      "2          передача       передача     0.0\n",
      "3          цифровых       цифровой     0.0\n",
      "4        технологий     технология     0.0\n",
      "...             ...            ...     ...\n",
      "19350  провозглашал  провозглашать   999.0\n",
      "19351          себя           себя   999.0\n",
      "19352        другом           друг   999.0\n",
      "19353          мира            мир   999.0\n",
      "19354             .              .   999.0\n",
      "\n",
      "[19355 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('C:\\\\Python programs\\\\dataset_ru_word_lemma2.csv')\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b785ea95-98ff-4653-a5bb-45ede72f8e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            stopword\n",
      "0                  а\n",
      "1          абсолютно\n",
      "2     авторизоваться\n",
      "3           активный\n",
      "4               алло\n",
      "...              ...\n",
      "1367               „\n",
      "1368               “\n",
      "1369               …\n",
      "1370               /\n",
      "1371             ...\n",
      "\n",
      "[1372 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_stopwords = pd.read_csv('C:\\\\Python programs\\\\stopwords_ru.csv')\n",
    "print(df_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac77727-0ae2-4951-8c5b-84e53450c85c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text     class\n",
      "0     Ваши дети совсем не хотят вылезать из реки. С ...     семья\n",
      "1     Одна из многих, очень многих вещей, о которых ...     семья\n",
      "2     Если вы дожили до этого этапа в воспитании дет...     семья\n",
      "3     Только представьте: ванная наполняется паром, ...     семья\n",
      "4     Когда дети были дома, вам приходилось быть обр...     семья\n",
      "...                                                 ...       ...\n",
      "3395  Православие.Ру В сентябре 2010 года Святейший ...    страна\n",
      "3396  Интерфакс Религия (interfax-religion.ru) В Мин...    страна\n",
      "3397  Окно возможностей В Эвенкинском муниципальном ...     наука\n",
      "3398  ИТАР-ТАСС. Новости из властных структур. Совет...  политика\n",
      "3399  Вечерний Магадан (Магадан) Охотское территориа...    страна\n",
      "\n",
      "[3400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test_docs = pd.read_csv('C:\\\\Python programs\\\\test_docs.csv')\n",
    "print(df_test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6c57a-895f-4589-bfdd-c88f8b73fd17",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$\\large\\textbf{Расстояние Левенштейна}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb16e4d-8b76-4cb8-b645-2d2298b0c05b",
   "metadata": {},
   "source": [
    "$$\n",
    "D(i, j) = \n",
    "\\begin{cases} \n",
    "\\max(i, j), \\quad \\quad \\quad \\quad \\quad \\quad  \\text{if} \\; \\min(i, j) = 0  \\\\\n",
    "\\min( \\quad \\quad \\quad  \\quad  \\quad \\quad \\quad \\quad \\text{otherwise}\\\\\n",
    "\\quad D(i, j - 1) + 1, \\\\\n",
    "\\quad D(i - 1, j) + 1, \\\\\n",
    "\\quad D(i - 1, j - 1) + (W_1[i] \\: \\neq \\: W_2 [j]) \\\\\n",
    ")\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3a1559-066f-47fb-8bba-04583e34f12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def lev_dist(w1, w2):\n",
    "    n, m = len(w1), len(w2)\n",
    "    mat = zeros([n + 1, m + 1], int)\n",
    "    mat[0, :] = array([i for i in range(m + 1)])\n",
    "    mat[:, 0] = array([i for i in range(n + 1)])\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            mat[i][j] = min(mat[i - 1][j] + 1, mat[i][j - 1] + 1,\n",
    "                            mat[i - 1][j - 1] + (w1[i - 1] != w2[j - 1]))\n",
    "    return mat[n][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be103b86-7964-414d-9040-ef997de429e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lemma_lev(w):\n",
    "    lemma = \"\"\n",
    "    len_w = len(w)\n",
    "    len_lemma = len_w\n",
    "    for word in lemma_dict[\"lemma\"]:\n",
    "        if abs(len_w - len(word)) >= len_lemma:\n",
    "            continue\n",
    "\n",
    "        dist = lev_dist(word, w)\n",
    "        if dist < len_lemma:\n",
    "            if dist == 0:\n",
    "                return word\n",
    "            lemma = word\n",
    "            len_lemma = dist\n",
    "\n",
    "    return lemma if lemma != \"\" else w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e02a5e-4512-4d08-b2c5-e792f8959df3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "гнездиться\n"
     ]
    }
   ],
   "source": [
    "print(lemma_lev(\"гнездился\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b08488-1c35-445d-b3d4-7a6968c1fe03",
   "metadata": {},
   "source": [
    "$$ \\large\\textbf{Поиск по словарю с удалением суффикса}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "123ace0b-d881-4d13-b425-cfeb41156567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def lemma_dbsra(w):\n",
    "    lemma = \"\"\n",
    "    for i in range(len(w)):\n",
    "        for j in range(len(w), i, -1):\n",
    "            if trie.hasKey(w[i:j]) and j - i > len(lemma):\n",
    "                lemma = w[i:j]\n",
    "    return lemma if lemma != \"\" else w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a105470f-10d3-4126-949d-24d2a0e0b8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+\n"
     ]
    }
   ],
   "source": [
    "print(lemma_dbsra(\"+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234673ff-ec0d-4882-83ae-5c54f1649744",
   "metadata": {},
   "source": [
    "$$ \\large\\textbf{Префиксное дерево}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c6f884-7fe9-4019-b2d8-4bffa85f6fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, value, child=None, key=None, end=False):\n",
    "        if child is not None and key is not None:\n",
    "            self.children = {key: child}\n",
    "        else:\n",
    "            self.children = {}\n",
    "        self.value = value\n",
    "        self._isEnd = end\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"keys = {list(self.children.keys())}, value = {self.value}, \\\n",
    "end = {self._isEnd}\"\n",
    "\n",
    "    def addChild(self, value, key):\n",
    "        self.children[key] = Node(value)\n",
    "\n",
    "    def hasChild(self, key):\n",
    "        if key in self.children.keys():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def getChild(self, key):\n",
    "        return self.children[key]\n",
    "\n",
    "    def setValue(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.value\n",
    "\n",
    "    def isEnd(self):\n",
    "        return self._isEnd\n",
    "\n",
    "    def getKeys(self):\n",
    "        return list(self.children.keys())\n",
    "\n",
    "    def setEnd(self):\n",
    "        self._isEnd = True\n",
    "\n",
    "\n",
    "class PrefixTrie(object):\n",
    "    def __init__(self, db=None):\n",
    "        self.root = Node('')\n",
    "\n",
    "        if db is not None:\n",
    "            for word in db:\n",
    "                self.insert(word, word)\n",
    "\n",
    "    def insertDict(self, db_form, db_lemma):\n",
    "        for i in range(len(db_form)):\n",
    "            self.insert(db_form[i], db_lemma[i])\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        node = self.root\n",
    "        lenght_key = len(key)\n",
    "        way = \"\"\n",
    "\n",
    "        for i in range(lenght_key):\n",
    "            char = key[i]\n",
    "            way += char\n",
    "            if not node.hasChild(char):\n",
    "                node.addChild(way, char)\n",
    "            node = node.getChild(char)\n",
    "        if (not node.isEnd()):\n",
    "            node.setValue(value)\n",
    "            node.setEnd()\n",
    "\n",
    "    def hasKey(self, key):\n",
    "        node = self.root\n",
    "\n",
    "        for i in range(len(key)):\n",
    "            char = key[i]\n",
    "            if node.hasChild(char):\n",
    "                node = node.getChild(char)\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        if node.isEnd():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def largestPrefix(self, key):\n",
    "        node = self.root\n",
    "        lemma = \"\"\n",
    "        lenght_key = len(key)\n",
    "\n",
    "        for i in range(lenght_key):\n",
    "            char = key[i]\n",
    "            if not node.hasChild(char):\n",
    "                break\n",
    "            node = node.getChild(char)\n",
    "            if node.isEnd():\n",
    "                lemma = node.getValue()\n",
    "\n",
    "        dif = lenght_key - len(lemma)\n",
    "        if dif != 0:\n",
    "            depth = 1\n",
    "            stack = [node.getChild(i) for i in node.getKeys()]\n",
    "            next_stack = []\n",
    "\n",
    "            while depth <= max(dif, int(lenght_key / 2)):\n",
    "                for elem in stack:\n",
    "                    if elem.isEnd():\n",
    "                        return elem.getValue()\n",
    "                    next_stack += [elem.getChild(i) for i in elem.getKeys()]\n",
    "\n",
    "                stack = next_stack.copy()\n",
    "                next_stack = []\n",
    "                depth += 1\n",
    "\n",
    "        return lemma if lemma != \"\" else key\n",
    "\n",
    "    @lru_cache\n",
    "    def getLemma(self, word):\n",
    "        prefix = \"\"\n",
    "        lemma = word\n",
    "        len_word = len(word)\n",
    "        min_dist = len_word\n",
    "\n",
    "        for i in range(len_word):\n",
    "            prefix += word[i]\n",
    "            new_lemma = self.largestPrefix(prefix)\n",
    "            dist = lev_dist(new_lemma, word)\n",
    "\n",
    "            if dist < min_dist and dist < len_word // 2:\n",
    "                if dist == 0:\n",
    "                    return new_lemma\n",
    "                lemma = new_lemma\n",
    "                min_dist = dist\n",
    "\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a435e9-cbe6-4a4a-9b0d-b18669a37712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trie = PrefixTrie(lemma_dict[\"lemma\"].apply(str.lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcadc325-f9e4-4586-9a1e-ccccff01e059",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сашин\n"
     ]
    }
   ],
   "source": [
    "print(trie.getLemma(\"сашин\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6512c35b-b1f0-4181-a445-ee697e7ba7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrefixTrie : 0.804, time : 6.318\n",
      "Pymorphy2 : 0.943, time : 6.096\n",
      "DBSRA : 0.608, time : 1.653\n"
     ]
    }
   ],
   "source": [
    "cnt_PT = 0\n",
    "cnt_PM2 = 0\n",
    "cnt_DBSRA = 0\n",
    "len_df = len(df_train.index)\n",
    "\n",
    "start_time = time.time()\n",
    "for word_id in range(len_df):\n",
    "    word = df_train['form'][word_id].lower()\n",
    "    lemma = df_train['lemma'][word_id].lower()\n",
    "\n",
    "    # if not lemma_dict[\"lemma\"].isin([lemma]).any():\n",
    "    #    len_df -= 1\n",
    "    # else:\n",
    "    res = trie.getLemma(word)\n",
    "    if res == lemma:\n",
    "        cnt_PT += 1\n",
    "\n",
    "time_PT = round(time.time() - start_time, 3)\n",
    "\n",
    "start_time = time.time()\n",
    "for word_id in range(len_df):\n",
    "    word = df_train['form'][word_id].lower()\n",
    "    lemma = df_train['lemma'][word_id].lower()\n",
    "    res = morph.parse(word)[0].normal_form\n",
    "\n",
    "    if res == lemma:\n",
    "        cnt_PM2 += 1\n",
    "time_PM2 = round(time.time() - start_time, 3)\n",
    "\n",
    "start_time = time.time()\n",
    "for word_id in range(len_df):\n",
    "    word = df_train['form'][word_id].lower()\n",
    "    lemma = df_train['lemma'][word_id].lower()\n",
    "    res = lemma_dbsra(word)\n",
    "\n",
    "    if res == lemma:\n",
    "        cnt_DBSRA += 1\n",
    "time_DBSRA = round(time.time() - start_time, 3)\n",
    "\n",
    "# PrefixTrie : 0.804, time : 6.253\n",
    "# PrefixTrie (если вычесть леммы не в словаре) : 0.833\n",
    "# Pymorphy2 : 0.943, time : 6.152\n",
    "# Pymorphy2 (если вычесть леммы не в словаре) : 0.99\n",
    "# DBSRA : 0.608, time : 1.6\n",
    "print(f\"PrefixTrie : {round(cnt_PT / len_df, 3)}, time : {time_PT}\")\n",
    "print(f\"Pymorphy2 : {round(cnt_PM2 / len_df, 3)}, time : {time_PM2}\")\n",
    "print(f\"DBSRA : {round(cnt_DBSRA / len_df, 3)}, time : {time_DBSRA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af61d4-7325-4d35-8ca9-5e001a3ea425",
   "metadata": {},
   "source": [
    "$$\\large \\textbf{Расстояние между документами}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b348b-b76b-4945-96a2-8e378ab4e798",
   "metadata": {},
   "source": [
    "$$\\textbf{Векторизация документов}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d3adb-e503-456e-a417-0ba49fae1b6a",
   "metadata": {},
   "source": [
    "В stopwordsiso есть 559 русских стоп-слов, найден больший словарь стоп-слов на 1352 слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0be7fe87-80a1-4361-ac2f-e7dec2cf13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_stopwords = PrefixTrie(df_stopwords['stopword'])\n",
    "\n",
    "\n",
    "def TFIDFn(list_of_docs):\n",
    "    \"\"\"\n",
    "    list_of_doc = [doc1, doc2, ...]\n",
    "    doc1 = [word1, word2, ...]\n",
    "    \"\"\"\n",
    "\n",
    "    count_of_docs = len(list_of_docs)\n",
    "    num_reg_exp = r'[-+]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][-+]?\\d+)?'\n",
    "\n",
    "    lemms_dict = {}\n",
    "    id_lemma_dict = {}\n",
    "    id_lemma = 0\n",
    "    list_docs_dict = []\n",
    "\n",
    "    with tqdm(total=count_of_docs*2, position=0, leave=True) as pbar:\n",
    "\n",
    "        for id_doc in range(count_of_docs):\n",
    "            doc_dict = {}\n",
    "\n",
    "            pbar.set_description(f\"Cycle: 1/2, Doc: {id_doc+1}/{count_of_docs}\")\n",
    "            pbar.update()\n",
    "\n",
    "            for id_word in range(len(list_of_docs[id_doc])):\n",
    "                word = list_of_docs[id_doc][id_word]\n",
    "                lemma = morph.parse(word)[0].normal_form\n",
    "\n",
    "                if trie_stopwords.hasKey(lemma) or trie_stopwords.hasKey(word) or \\\n",
    "                        re.fullmatch(num_reg_exp, word) is not None:\n",
    "                    continue\n",
    "\n",
    "                if lemma not in lemms_dict.keys():\n",
    "                    lemms_dict[lemma] = [id_lemma, [id_doc]]\n",
    "                    id_lemma_dict[id_lemma] = lemma\n",
    "                    id_lemma += 1\n",
    "                elif lemms_dict[lemma][1][-1] < id_doc:\n",
    "                    lemms_dict[lemma][1] += [id_doc]\n",
    "\n",
    "                id_this_lemma = lemms_dict[lemma][0]\n",
    "\n",
    "                if id_this_lemma not in doc_dict.keys():\n",
    "                    doc_dict[id_this_lemma] = 1\n",
    "                else:\n",
    "                    doc_dict[id_this_lemma] += 1\n",
    "\n",
    "            list_docs_dict += [doc_dict]\n",
    "\n",
    "        for id_doc in range(count_of_docs):\n",
    "\n",
    "            pbar.set_description(f\"Cycle: 2/2, Doc: {id_doc+1}/{count_of_docs}\")\n",
    "            pbar.update()\n",
    "\n",
    "            count_words = len(list_docs_dict[id_doc].keys())\n",
    "            norm_this_docs = 0\n",
    "\n",
    "            for key in list_docs_dict[id_doc].keys():\n",
    "                lemma = id_lemma_dict[key]\n",
    "                res = list_docs_dict[id_doc][key] \\\n",
    "                    / count_words * log(count_of_docs / len(lemms_dict[lemma][1]))\n",
    "\n",
    "                list_docs_dict[id_doc][key] = res\n",
    "                norm_this_docs += res ** 2\n",
    "\n",
    "            if norm_this_docs != 0:\n",
    "                norm_this_docs = norm_this_docs ** 0.5\n",
    "                for key in list_docs_dict[id_doc].keys():\n",
    "                    list_docs_dict[id_doc][key] /= norm_this_docs\n",
    "\n",
    "    return list_docs_dict, id_lemma  # лист документов и размерность пространства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0d70d133-cb08-4e5c-b02f-701adf5f7ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cycle: 2/2, Doc: 2/2: 100%|█████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 372.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([{0: 0.4472135954999579, 1: 0.8944271909999159, 2: 0.0}, {2: 0.0}], 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(TFIDFn([['приниматься', 'ись', 'ись', 'глядел'], ['ты', 'сидел', 'и', 'глядел']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddbd9235-2848-4f97-99d5-aa0dbb89cc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_docs = [list(df_train.loc[df_train['id_sen'] == id_sen, 'form']) for id_sen in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dd00578b-db1c-498e-b163-52b925c5e5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cycle: 2/2, Doc: 1000/1000: 100%|█████████████████████████████████████████████████| 2000/2000 [00:13<00:00, 145.46it/s]\n"
     ]
    }
   ],
   "source": [
    "vect_list, dim = TFIDFn(list_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d0c1a6f6-7da0-4a44-98dc-e9d4a902625d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4467\n"
     ]
    }
   ],
   "source": [
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a339b0-549c-46d6-976c-cf8278360a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prod_vect(vect1, vect2):\n",
    "    res = 0\n",
    "    for key in vect1.keys() & vect2.keys():\n",
    "        res += vect1[key] * vect2[key]\n",
    "    return 1 - res\n",
    "\n",
    "\n",
    "def euclide_dist(vect1, vect2):\n",
    "    res = 0\n",
    "    inters = vect1.keys() & vect2.keys()\n",
    "    for key in vect1.keys():\n",
    "        if key not in inters:\n",
    "            res += vect1[key] ** 2\n",
    "    for key in vect2.keys():\n",
    "        if key not in inters:\n",
    "            res += vect2[key] ** 2\n",
    "    for key in inters:\n",
    "        res += (vect1[key] - vect2[key]) ** 2\n",
    "\n",
    "    return res ** 0.5\n",
    "\n",
    "\n",
    "def dist_matrix(vect_list, metric=prod_vect):\n",
    "    len_vect_list = len(vect_list)\n",
    "    dist_docs = {}\n",
    "\n",
    "    with tqdm(total=len_vect_list*(len_vect_list-1)//2, position=0, leave=True) as pbar:\n",
    "        for i in range(len_vect_list):\n",
    "            vect1 = vect_list[i]\n",
    "            for j in range(i + 1, len_vect_list):\n",
    "                vect2 = vect_list[j]\n",
    "                dist_docs[(i, j)] = metric(vect1, vect2)\n",
    "\n",
    "                pbar.update()\n",
    "\n",
    "    return dist_docs\n",
    "\n",
    "\n",
    "def save_dist_matrix(dist_matrix, path=\"C:\\\\Users\\\\user\\\\Desktop\\\\\", name=\"dist_matrix\"):\n",
    "    file = open(path + name + \".txt\", \"w\")\n",
    "    for key in dist_matrix.keys():\n",
    "        file.write(f\"{key[0]}:{key[1]}:{dist_matrix[key]}\\n\")\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def open_dist_matrix(path=\"C:\\\\Users\\\\user\\\\Desktop\\\\dist_matrix.txt\"):\n",
    "    file = open(path, \"r\")\n",
    "    dist_matrix = {}\n",
    "\n",
    "    for line in file:\n",
    "        id_res = line.split(\":\")\n",
    "        dist_matrix[(int(id_res[0]), int(id_res[1]))] = float(id_res[2])\n",
    "\n",
    "    file.close()\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41459701-c1f2-43f7-a9d0-090d26be9779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = dist_matrix(vect_list)\n",
    "cnt = 5\n",
    "for key in d.keys():\n",
    "    if d[key] > 0.5:\n",
    "        print(list_docs[key[0]])\n",
    "        print(list_docs[key[1]])\n",
    "        print(d[key])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "80faca1b-73c5-44e0-8bff-c4e80be0e3e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dist_matrix(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "765fdca3-6e3a-4368-8a13-e87c2d9248aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5778300\n"
     ]
    }
   ],
   "source": [
    "r = open_dist_matrix()\n",
    "print(len(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f7133b-b448-40b8-bea2-0f11d1ca1c01",
   "metadata": {},
   "source": [
    "Слишком большая размерность векторов и большая разряженность. Для оптимизации по памяти при больших объемах можно хранить только ненулевые значения в разряженных таблицах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f85b12-61e1-4d80-9bad-619b0620a260",
   "metadata": {},
   "source": [
    "Используем алгоритм TF-IDF:\n",
    "$$\\text{TF-IDF}(w, d) = \\text{TF}(w, d) \\cdot \\text{IDF}(w),$$\n",
    "где $\\text{TF}(w, d)$ - частота слова w в документе d, $\\text{IDF}(w)$ - логарифм отношения общего количества документов к количеству документов со словом w."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a35839-54d5-4730-9751-d4ba2304e05b",
   "metadata": {},
   "source": [
    "$$\\large \\textbf{Класстеризация документов}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560dd4f0-eb20-4136-a525-30a8506c6cd6",
   "metadata": {},
   "source": [
    "Токенизация - Леммализация - Векторизация - TF-IDF - \n",
    "(Метрики: Метод Косинусов, Евклидово расстояние) - (Класстеризация: K-средних, DBSCAN, нейроночки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10d06c37-4e9d-4b10-a7ff-961d5212a6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    res = re.split(r'\\W', doc.lower())\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            res.remove('')\n",
    "        except ValueError:\n",
    "            return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95095986-41fe-4787-b402-fcf99078aea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ваши', 'дети', 'совсем', 'не', 'хотят', 'вылезать', 'из', 'реки', 'с', 'каждым', 'днем', 'допустимое', 'время', 'просмотра', 'телевизора', 'становится', 'все', 'больше', 'и', 'больше', 'вы', 'не', 'уверены', 'что', 'способны', 'вынести', 'хотя', 'бы', 'еще', 'один', 'крик', 'его', 'половина', 'больше', 'моей']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(df_test_docs['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bbed08e-6318-4218-b69d-1369bfb62733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_docs_test = [tokenize(df_test_docs['text'][i]) for i in range(len(df_test_docs.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c683bef-eeea-410c-840c-f6f11262d6fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cycle: 2/2, Doc: 3400/3400: 100%|██████████████████████████████████████████████████| 6800/6800 [05:23<00:00, 21.01it/s]\n"
     ]
    }
   ],
   "source": [
    "vect_docs_test, dim = TFIDFn(list_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82a654cc-e356-41e5-bc99-45c1e2f0466a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36217 [{0: 0.1586698379117062, 1: 0.4482251888500325, 2: 0.30363640681942283, 3: 0.34565175219632255, 4: 0.28156737056940456, 5: 0.3340319509527152, 6: 0.2552100268440207, 7: 0.23361914356988459, 8: 0.29736257886067563, 9: 0.4040492142022535}, {10: 0.27264399391688626, 11: 0.2108448556020082, 12: 0.12719230255212993, 13: 0.14528390387922988, 14: 0.22660783880457305, 15: 0.1382759911284418, 16: 0.19098584537932095, 17: 0.2083358366894893, 18: 0.2535548365747409, 19: 0.14250584375420736, 20: 0.21951985125709236, 21: 0.1420615383461895, 22: 0.3416341244050081, 23: 0.24646684902726027, 24: 0.2622298322298251, 25: 0.13482657028317926, 26: 0.17369810596403937, 27: 0.09260870094538967, 28: 0.14932663918429048, 29: 0.31612382777016096, 30: 0.13519506877725196, 31: 0.21352704317523685, 32: 0.22660783880457305}, {33: 0.22109273147285796, 34: 0.14490090686727164, 35: 0.2010914295890518, 0: 0.19496169212073097, 36: 0.23235688054832207, 37: 0.16077683331519121, 38: 0.15940283786861995, 39: 0.23235688054832207, 40: 0.15616505594273578, 41: 0.10810234538332916, 42: 0.1702194980463635, 43: 0.08824700770348035, 44: 0.15940283786861995, 45: 0.13434226971463775, 46: 0.27537288251962533, 47: 0.2912488089675449, 48: 0.2369686579207775, 49: 0.1702194980463635, 50: 0.31838888449092856, 51: 0.27537288251962533, 52: 0.17700392671221354, 53: 0.2912488089675449, 54: 0.19235427678070977}, {55: 0.25628736401655333, 56: 0.3634707148450848, 57: 0.29153056367916325, 58: 0.2295646902963259, 59: 0.3634707148450848, 60: 0.2058461757146805, 61: 0.29153056367916325, 62: 0.33248777815366615, 63: 0.1913732401066965, 64: 0.33248777815366615, 65: 0.2764906150246314, 66: 0.18197326053351337, 67: 0.19432149063371595}, {0: 0.1332981127156947, 68: 0.1921194310678, 69: 0.25326900629393434, 70: 0.3982619984855933, 71: 0.18085990546560035, 72: 0.25696298614435076, 73: 0.26987515749432917, 74: 0.3492024445386816, 75: 0.22700033348103427, 76: 0.30698727738697124, 77: 0.14305987712088833, 78: 0.4353741183782353, 45: 0.18370348365477554, 79: 0.19878289068176777}]\n"
     ]
    }
   ],
   "source": [
    "print(dim, vect_docs_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "94c1fb1a-0695-4ee2-95aa-accd81029f34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 5778300/5778300 [00:31<00:00, 185836.29it/s]\n"
     ]
    }
   ],
   "source": [
    "t = dist_matrix(vect_docs_test)\n",
    "save_dist_matrix(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32a1c4-b3fe-4f15-b1dc-7633c274571a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt = 5\n",
    "for key in t.keys():\n",
    "    if t[key] < 0.1:\n",
    "        print(df_test_docs['text'][key[0]])\n",
    "        print()\n",
    "        print(df_test_docs['text'][key[1]])\n",
    "        print(t[key])\n",
    "        print(df_test_docs['class'][key[0]], df_test_docs['class'][key[1]])\n",
    "        print(\"\\n---------------------------------------------------------------\\n\")\n",
    "\n",
    "        cnt -= 1\n",
    "        if cnt == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8791534-ca33-4743-a3e4-900a2554022e",
   "metadata": {},
   "source": [
    "$$\\large \\textbf{Кластеризация}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c46206d6-f1ea-426f-847b-4438f284359a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_id, test_id = [], []\n",
    "for i in range(len(vect_docs_test)):\n",
    "    if rint(1, 5) == 1:\n",
    "        test_id += [i]\n",
    "    else:\n",
    "        train_id += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6c71b484-da70-4977-8857-0d837d024d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_vect(vect1, vect2, metric):\n",
    "    res = {}\n",
    "    inters = vect1.keys() & vect2.keys()\n",
    "\n",
    "    for key in vect1.keys():\n",
    "        res[key] = vect1[key]\n",
    "    for key in vect2.keys():\n",
    "        if key in inters:\n",
    "            res[key] += vect2[key]\n",
    "        else:\n",
    "            res[key] = vect2[key]\n",
    "\n",
    "    if metric != euclide_dist:\n",
    "        norm = sum(map(lambda x: x ** 2, res.values())) ** 0.5\n",
    "        for key in res.keys():\n",
    "            res[key] /= norm\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def norm(vect):\n",
    "    res = 0\n",
    "    for key in vect.keys():\n",
    "        res += vect[key] ** 2\n",
    "    return res ** 0.5\n",
    "\n",
    "\n",
    "def dev_vect_on_num(vect, num):\n",
    "    res = {}\n",
    "    for key in vect.keys():\n",
    "        res[key] = vect[key] / num\n",
    "    return res\n",
    "\n",
    "\n",
    "def mKavg(vect_docs, train_id, test_id, name_classes, metric=prod_vect):\n",
    "    # нужно согласовать норму с косинусной метрикой\n",
    "    # изменить сложение для косинусной метрики\n",
    "\n",
    "    cnt_classters = len(name_classes)\n",
    "    classter_centers = [{} for i in range(cnt_classters)]\n",
    "    classter_id_vect = {}\n",
    "    name_classes = dict([(name_classes[i], i) for i in range(cnt_classters)])\n",
    "    cnt_train_doc_in_class = dict([(i, 0) for i in range(cnt_classters)])\n",
    "\n",
    "    for id_doc in train_id:\n",
    "        classter_id = name_classes[df_test_docs['class'][id_doc]]\n",
    "        classter_centers[classter_id] = \\\n",
    "            sum_vect(classter_centers[classter_id], vect_docs[id_doc], metric)\n",
    "        cnt_train_doc_in_class[classter_id] += 1\n",
    "\n",
    "    if metric == euclide_dist:\n",
    "        for classter_id in range(cnt_classters):\n",
    "            classter_centers[classter_id] = \\\n",
    "                dev_vect_on_num(classter_centers[classter_id], cnt_train_doc_in_class[classter_id])\n",
    "\n",
    "    cnt_doc = len(vect_docs)\n",
    "    changed = True\n",
    "    cnt_cycle = 0\n",
    "\n",
    "    while changed:\n",
    "        changed = False\n",
    "        cnt_cycle += 1\n",
    "        print(cnt_cycle)\n",
    "        if cnt_cycle == 21:\n",
    "            break\n",
    "\n",
    "        for i in range(cnt_classters):\n",
    "            classter_id_vect[i] = []\n",
    "\n",
    "        for id_doc in range(cnt_doc):\n",
    "            doc = vect_docs[id_doc]\n",
    "            min_dist = metric(doc, classter_centers[0]) ** 2\n",
    "            classter = 0\n",
    "\n",
    "            for id_classter in range(1, cnt_classters):\n",
    "                dist = metric(doc, classter_centers[id_classter]) ** 2\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    classter = id_classter\n",
    "\n",
    "            classter_id_vect[classter] += [id_doc]\n",
    "\n",
    "        for i in range(cnt_classters):\n",
    "            new_class_center = {}\n",
    "            for id_doc in classter_id_vect[i]:\n",
    "                new_class_center = sum_vect(new_class_center, vect_docs[id_doc], metric)\n",
    "\n",
    "            if metric == euclide_dist:\n",
    "                new_class_center = dev_vect_on_num(new_class_center, len(classter_id_vect[i]))\n",
    "\n",
    "            if not changed and classter_centers[i] != new_class_center:\n",
    "                changed = True\n",
    "\n",
    "            classter_centers[i] = new_class_center\n",
    "\n",
    "    return classter_id_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "836c69e9-7397-4014-8055-29e28e9bcd04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def method_min_dist(vect_docs, train_id, test_id, name_classes, metric=prod_vect):\n",
    "    cnt_classters = len(name_classes)\n",
    "    classter_centers = [{} for i in range(cnt_classters)]\n",
    "    classter_id_vect = {}\n",
    "    name_classes = dict([(name_classes[i], i) for i in range(cnt_classters)])\n",
    "    cnt_train_doc_in_class = dict([(i, 0) for i in range(cnt_classters)])\n",
    "\n",
    "    for id_doc in train_id:\n",
    "        classter_id = name_classes[df_test_docs['class'][id_doc]]\n",
    "        classter_centers[classter_id] = \\\n",
    "            sum_vect(classter_centers[classter_id], vect_docs[id_doc], metric)\n",
    "        cnt_train_doc_in_class[classter_id] += 1\n",
    "\n",
    "    if metric == euclide_dist:\n",
    "        for classter_id in range(cnt_classters):\n",
    "            classter_centers[classter_id] = \\\n",
    "                dev_vect_on_num(classter_centers[classter_id], cnt_train_doc_in_class[classter_id])\n",
    "\n",
    "    for i in range(cnt_classters):\n",
    "        classter_id_vect[i] = []\n",
    "\n",
    "    for id_doc in test_id:\n",
    "        doc = vect_docs[id_doc]\n",
    "        min_dist = metric(doc, classter_centers[0])\n",
    "        classter = 0\n",
    "\n",
    "        for id_classter in range(1, cnt_classters):\n",
    "            dist = metric(doc, classter_centers[id_classter])\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                classter = id_classter\n",
    "\n",
    "        classter_id_vect[classter] += [id_doc]\n",
    "\n",
    "    return classter_id_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccf057be-e3b3-483c-8bb4-40339929fa19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['семья', 'реклама', 'недвижимость', 'здоровье', 'политика', 'культура', 'спорт', 'техника', 'экономика', 'происшествия', 'автомобили', 'страна', 'наука']\n"
     ]
    }
   ],
   "source": [
    "name_classes = list(df_test_docs['class'].unique())\n",
    "print(name_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9f381ce2-679d-4734-87d8-9be846318f52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.9999999999999993 0\n",
      "1.0000000000000007 1\n",
      "1.0000000000000013 2\n",
      "1.0000000000000002 3\n",
      "0.9999999999999994 4\n",
      "1.0 5\n",
      "1.0000000000000002 6\n",
      "0.9999999999999999 7\n",
      "1.0000000000000004 8\n",
      "1.0000000000000002 9\n",
      "1.0000000000000004 10\n",
      "0.9999999999999983 11\n",
      "1.0000000000000007 12\n",
      "2\n",
      "0.9999999999999999 0\n",
      "0.9999999999999994 1\n",
      "0.999999999999999 2\n",
      "1.0 3\n",
      "0.999999999999998 4\n",
      "1.0000000000000024 5\n",
      "1.0 6\n",
      "0.9999999999999997 7\n",
      "0.9999999999999998 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m classters_vect \u001b[38;5;241m=\u001b[39m \u001b[43mmKavg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvect_docs_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[126], line 85\u001b[0m, in \u001b[0;36mmKavg\u001b[1;34m(vect_docs, train_id, test_id, name_classes, metric)\u001b[0m\n\u001b[0;32m     83\u001b[0m new_class_center \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m id_doc \u001b[38;5;129;01min\u001b[39;00m classter_id_vect[i]:\n\u001b[1;32m---> 85\u001b[0m     new_class_center \u001b[38;5;241m=\u001b[39m \u001b[43msum_vect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_class_center\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvect_docs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_doc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m euclide_dist:\n\u001b[0;32m     88\u001b[0m     new_class_center \u001b[38;5;241m=\u001b[39m dev_vect_on_num(new_class_center, \u001b[38;5;28mlen\u001b[39m(classter_id_vect[i]))\n",
      "Cell \u001b[1;32mIn[126], line 16\u001b[0m, in \u001b[0;36msum_vect\u001b[1;34m(vect1, vect2, metric)\u001b[0m\n\u001b[0;32m     14\u001b[0m     norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, res\u001b[38;5;241m.\u001b[39mvalues())) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m---> 16\u001b[0m         res[key] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m norm\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classters_vect = mKavg(vect_docs_test, train_id, test_id, name_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3d6ca9c7-471f-46d3-9aef-07abb311091f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classters_vect = method_min_dist(vect_docs_test, train_id, test_id, name_classes, euclide_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84d7d1-a994-4869-ae23-96e72c8a2d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id1, id2 = classters_vect[1][17], classters_vect[1][20]\n",
    "print(df_test_docs['text'][id1])\n",
    "print()\n",
    "print(df_test_docs['text'][id2])\n",
    "print(df_test_docs['class'][id1], df_test_docs['class'][id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a96cab07-5b35-4eb5-a6e1-d36f0d99823a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'семья': 10, 'реклама': 1, 'страна': 2, 'экономика': 1, 'спорт': 1}\n",
      "15 семья\n",
      "0.6666666666666666\n",
      "\n",
      "{'реклама': 18, 'недвижимость': 2, 'происшествия': 2, 'страна': 3, 'техника': 1, 'экономика': 3}\n",
      "29 реклама\n",
      "0.6206896551724138\n",
      "\n",
      "{'недвижимость': 12, 'происшествия': 3, 'страна': 4, 'культура': 1}\n",
      "20 недвижимость\n",
      "0.6\n",
      "\n",
      "{'семья': 4, 'реклама': 4, 'недвижимость': 2, 'здоровье': 20, 'культура': 42, 'политика': 46, 'спорт': 17, 'техника': 32, 'экономика': 12, 'происшествия': 16, 'страна': 13, 'автомобили': 5}\n",
      "213 здоровье\n",
      "0.09389671361502347\n",
      "\n",
      "{'политика': 70}\n",
      "70 политика\n",
      "1.0\n",
      "\n",
      "{'культура': 31}\n",
      "31 культура\n",
      "1.0\n",
      "\n",
      "{'спорт': 60, 'происшествия': 1}\n",
      "61 спорт\n",
      "0.9836065573770492\n",
      "\n",
      "{'автомобили': 1, 'техника': 28, 'политика': 1, 'происшествия': 5}\n",
      "35 техника\n",
      "0.8\n",
      "\n",
      "{'экономика': 29}\n",
      "29 экономика\n",
      "1.0\n",
      "\n",
      "{'происшествия': 74, 'автомобили': 8}\n",
      "82 происшествия\n",
      "0.9024390243902439\n",
      "\n",
      "{'автомобили': 35}\n",
      "35 автомобили\n",
      "1.0\n",
      "\n",
      "{'политика': 9, 'автомобили': 2, 'происшествия': 6, 'экономика': 2, 'страна': 8, 'культура': 3}\n",
      "30 страна\n",
      "0.26666666666666666\n",
      "\n",
      "{'наука': 40, 'техника': 1}\n",
      "41 наука\n",
      "0.975609756097561\n",
      "\n",
      "0.6295224312590448\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "den = 0\n",
    "for i in range(13):\n",
    "    local_acc = 0\n",
    "    cnt_vect = 0\n",
    "    dct = {}\n",
    "    for id_doc in classters_vect[i]:\n",
    "        if id_doc not in test_id:\n",
    "            continue\n",
    "        den += 1\n",
    "        cnt_vect += 1\n",
    "        target = df_test_docs['class'][id_doc]\n",
    "        if target == name_classes[i]:\n",
    "            acc += 1\n",
    "            local_acc += 1\n",
    "\n",
    "        if target not in dct.keys():\n",
    "            dct[target] = 1\n",
    "        else:\n",
    "            dct[target] += 1\n",
    "    print(dct)\n",
    "    print(cnt_vect, name_classes[i])\n",
    "    print(local_acc / cnt_vect)\n",
    "    print()\n",
    "print(acc / den)\n",
    "# mKavg(cos): для train = 100% 0.19117647058823528\n",
    "# mKavg(cos): для train = 80% 0.18668596237337193\n",
    "# mKavg(euc): для train = 80% 0.6295224312590448\n",
    "# min_dist(cos): для train = 80% 0.3140376266280753\n",
    "# min_dist(euc): для train = 80% 0.8422575976845152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf88ec-9d12-4d09-88fd-14c76d1e3169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
