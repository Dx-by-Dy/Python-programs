{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "185ad47a-6530-449c-a109-88b2822df452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=['alt.atheism',\n",
    "                                                  # 'comp.graphics',\n",
    "                                                  # 'comp.os.ms-windows.misc',\n",
    "                                                  'comp.sys.ibm.pc.hardware',\n",
    "                                                  # 'comp.sys.mac.hardware',\n",
    "                                                  # 'comp.windows.x',\n",
    "                                                  'misc.forsale',\n",
    "                                                  'rec.autos',\n",
    "                                                  # 'rec.motorcycles',\n",
    "                                                  'rec.sport.baseball'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10a7df33-8a52-4acd-8461-dfc1d64a0ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(x):\n",
    "    return train_test_split(x, newsgroups_train.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b89af041-cdc7-44f6-9e47-6abbd2a75746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenize_data = [nltk.word_tokenize(newsgroups_train.data[i])\n",
    "                 for i in range(len(newsgroups_train.data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb90c3a5-5712-43b5-9d7f-c28cae8cc0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_reg_exp = r'[-+]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][-+]?\\d+)?'\n",
    "stop_words = stopwords.words('english') +\\\n",
    "            [\"(\", \")\", \":\", \"@\", \"?\", \",\", \"|\", \">\", \"<\", \"]\",\n",
    "             \"[\", \".\", \"``\", \"\\'\\'\", \"--\", \"!\", \"-\", \"*\", \"..\"]\n",
    "\n",
    "\n",
    "def delete_stopword(listw):\n",
    "    res = []\n",
    "    for word in listw:\n",
    "        word = word.lower()\n",
    "        if word not in stop_words and re.fullmatch(num_reg_exp, word) is None:\n",
    "            res += [word]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcb6f77f-02e4-40b2-ac05-3d1d4d8f5af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenize_data = [delete_stopword(tokenize_data[i])\n",
    "                 for i in range(len(tokenize_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0e203bd-dde5-49b6-bc3d-3a3af0c768a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [(tokenize_data[i], newsgroups_train.target[i]) for i in range(len(tokenize_data))]\n",
    "shuffle(data)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    tokenize_data[i] = data[i][0]\n",
    "    newsgroups_train.target[i] = data[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6525d3df-6798-4ae1-8dfd-a1999905ac7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatize_data = [list(map(lemmatizer.lemmatize, tokenize_data[i]))\n",
    "                  for i in range(len(tokenize_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "814acd3c-4a3e-4824-8bb8-c593c404be69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stemize_data = [list(map(stemmer.stem, tokenize_data[i]))\n",
    "                for i in range(len(tokenize_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb1b44a2-47a1-4f55-8260-f4ad992297fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vocab(data):\n",
    "    vocab = []\n",
    "    for sent in data:\n",
    "        vocab += sent\n",
    "    vocab = list(set(vocab))\n",
    "\n",
    "    idx_word = {}\n",
    "    for i in range(len(vocab)):\n",
    "        idx_word[vocab[i]] = i\n",
    "\n",
    "    return vocab, idx_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37bc9297-e86f-4834-b8f0-658ddd4afbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize01(data):\n",
    "\n",
    "    vocab, idx_word = get_vocab(data)\n",
    "\n",
    "    vectorize01_data = []\n",
    "    len_vocab = len(vocab)\n",
    "    count_doc = len(data)\n",
    "\n",
    "    with tqdm(total=count_doc, position=0, leave=True) as pbar:\n",
    "        for i in range(count_doc):\n",
    "\n",
    "            pbar.set_description(f\"Doc: {i+1}/{count_doc}\")\n",
    "            pbar.update()\n",
    "\n",
    "            doc = [0] * len_vocab\n",
    "            for word in data[i]:\n",
    "                doc[idx_word[word]] = 1\n",
    "\n",
    "            vectorize01_data += [doc]\n",
    "\n",
    "    return vectorize01_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8b1dd0b-182b-4918-b2e1-23491a68645c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize0n(data):\n",
    "    vocab, idx_word = get_vocab(data)\n",
    "\n",
    "    vectorize0n_data = []\n",
    "    len_vocab = len(vocab)\n",
    "    count_doc = len(data)\n",
    "\n",
    "    with tqdm(total=count_doc, position=0, leave=True) as pbar:\n",
    "        for i in range(count_doc):\n",
    "\n",
    "            pbar.set_description(f\"Doc: {i+1}/{count_doc}\")\n",
    "            pbar.update()\n",
    "\n",
    "            doc = [0] * len_vocab\n",
    "            len_doc = len(data[i])\n",
    "            for word in data[i]:\n",
    "                doc[idx_word[word]] += 1 / len_doc\n",
    "\n",
    "            vectorize0n_data += [doc]\n",
    "\n",
    "    return vectorize0n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82f5e549-22ff-46f6-9f13-1ecd840c11e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_docs_with_word(word, data):\n",
    "    res = 0\n",
    "    for doc in data:\n",
    "        if word in doc:\n",
    "            res += 1\n",
    "    return res\n",
    "\n",
    "\n",
    "def tf_idf(data):\n",
    "    vocab, idx_word = get_vocab(data)\n",
    "\n",
    "    vectorize_data = []\n",
    "    len_vocab = len(vocab)\n",
    "    count_doc = len(data)\n",
    "    list_count_docs_with_word = [0 for i in range(len_vocab)]\n",
    "\n",
    "    with tqdm(total=count_doc, position=0, leave=True) as pbar:\n",
    "        for i in range(count_doc):\n",
    "            pbar.set_description(f\"Cycle: 1/2, Doc: {i+1}/{count_doc}\")\n",
    "            pbar.update()\n",
    "\n",
    "            for word in set(data[i]):\n",
    "                list_count_docs_with_word[idx_word[word]] += 1\n",
    "\n",
    "    idf = [log(count_doc / elem) for elem in list_count_docs_with_word]\n",
    "\n",
    "    with tqdm(total=count_doc, position=0, leave=True) as pbar:\n",
    "        for i in range(count_doc):\n",
    "\n",
    "            pbar.set_description(f\"Cycle: 2/2, Doc: {i+1}/{count_doc}\")\n",
    "            pbar.update()\n",
    "\n",
    "            doc = [0 for i in range(len_vocab)]\n",
    "            len_doc = len(data[i])\n",
    "\n",
    "            for word in data[i]:\n",
    "                doc[idx_word[word]] += 1 / len_doc\n",
    "\n",
    "            for word in set(data[i]):\n",
    "                doc[idx_word[word]] *= idf[idx_word[word]]\n",
    "\n",
    "            vectorize_data += [doc]\n",
    "\n",
    "    return vectorize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d7515f3-d05f-4a95-b789-90b704a0afc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_res(type_doc, type_vec, data):\n",
    "    x_train, x_test, y_train, y_test = split_data(data)\n",
    "    clf = DecisionTreeClassifier(random_state=42, max_depth=20)\n",
    "    clf.fit(x_train, y_train)\n",
    "    acc_test = f1_score(y_true=y_test, y_pred=clf.predict(x_test), average=\"micro\")\n",
    "    print(f\"{type_doc} текст, векторизация {type_vec}: {round(acc_test, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b53fde7-1829-4714-98e2-ae279af1357e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doc: 2846/2846: 100%|█████████████████████████████████████████████████████████████| 2846/2846 [00:06<00:00, 417.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Необработанный текст, векторизация 0-1: 0.779\n"
     ]
    }
   ],
   "source": [
    "vectorize01_void_data = vectorize01(tokenize_data)\n",
    "print_res(\"Необработанный\", \"0-1\", vectorize01_void_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0267f8f7-e9e3-411c-8ef7-0a3d587ce817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doc: 2846/2846: 100%|█████████████████████████████████████████████████████████████| 2846/2846 [00:08<00:00, 327.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Необработанный текст, векторизация 0-n: 0.758\n"
     ]
    }
   ],
   "source": [
    "vectorize0n_void_data = vectorize0n(tokenize_data)\n",
    "print_res(\"Необработанный\", \"0-n\", vectorize0n_void_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "898c21e7-da05-4a1e-bff1-ec4e0930d73f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cycle: 1/2, Doc: 2846/2846: 100%|█████████████████████████████████████████████████| 2846/2846 [00:05<00:00, 545.12it/s]\n",
      "Cycle: 2/2, Doc: 2846/2846: 100%|█████████████████████████████████████████████████| 2846/2846 [00:18<00:00, 150.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Необработанный текст, векторизация tf-idf: 0.747\n"
     ]
    }
   ],
   "source": [
    "vectorize_tfidf_void_data = tf_idf(tokenize_data)\n",
    "print_res(\"Необработанный\", \"tf-idf\", vectorize_tfidf_void_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c5b02e5-87e4-4571-9bae-63b5cca1ce37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doc: 2846/2846: 100%|█████████████████████████████████████████████████████████████| 2846/2846 [00:08<00:00, 343.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стеммированный текст, векторизация 0-1: 0.765\n"
     ]
    }
   ],
   "source": [
    "vectorize01_stemize_data = vectorize01(stemize_data)\n",
    "print_res(\"Стеммированный\", \"0-1\", vectorize01_stemize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23e601bc-c317-47b6-862d-5e4484914ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doc: 2846/2846: 100%|█████████████████████████████████████████████████████████████| 2846/2846 [00:09<00:00, 303.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стеммированный текст, векторизация 0-n: 0.774\n"
     ]
    }
   ],
   "source": [
    "vectorize0n_stemize_data = vectorize0n(stemize_data)\n",
    "print_res(\"Стеммированный\", \"0-n\", vectorize0n_stemize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "779db4b6-ddbe-4177-a4db-8a17ddf3a0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cycle: 1/2, Doc: 2846/2846: 100%|█████████████████████████████████████████████████| 2846/2846 [00:05<00:00, 487.14it/s]\n",
      "Cycle: 2/2, Doc: 2846/2846: 100%|█████████████████████████████████████████████████| 2846/2846 [00:17<00:00, 158.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стеммированный текст, векторизация tf-idf: 0.77\n"
     ]
    }
   ],
   "source": [
    "vectorize_tfidf_stemize_data = tf_idf(stemize_data)\n",
    "print_res(\"Стеммированный\", \"tf-idf\", vectorize_tfidf_stemize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "587a78c6-9499-4121-abf2-01b55429924a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doc: 2846/2846: 100%|█████████████████████████████████████████████████████████████| 2846/2846 [00:10<00:00, 278.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лемматизированный текст, векторизация 0-1: 0.761\n"
     ]
    }
   ],
   "source": [
    "vectorize01_lemmatize_data = vectorize01(lemmatize_data)\n",
    "print_res(\"Лемматизированный\", \"0-1\", vectorize01_lemmatize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41d04b12-c1e7-4881-be79-f0111b98e664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doc: 2846/2846: 100%|█████████████████████████████████████████████████████████████| 2846/2846 [00:07<00:00, 358.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лемматизированный текст, векторизация 0-n: 0.767\n"
     ]
    }
   ],
   "source": [
    "vectorize0n_lemmatize_data = vectorize0n(lemmatize_data)\n",
    "print_res(\"Лемматизированный\", \"0-n\", vectorize0n_lemmatize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c061518d-2a2d-413a-b7c8-b86c5fd8bb1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cycle: 1/2, Doc: 2846/2846: 100%|█████████████████████████████████████████████████| 2846/2846 [00:05<00:00, 540.67it/s]\n",
      "Cycle: 2/2, Doc: 2846/2846: 100%|█████████████████████████████████████████████████| 2846/2846 [00:20<00:00, 137.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лемматизированный текст, векторизация tf-idf: 0.768\n"
     ]
    }
   ],
   "source": [
    "vectorize_tfidf_lemmatize_data = tf_idf(lemmatize_data)\n",
    "print_res(\"Лемматизированный\", \"tf-idf\", vectorize_tfidf_lemmatize_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedcde14-0b7f-42be-9056-47b65a7a992a",
   "metadata": {},
   "source": [
    "## Результаты (для 3 классов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d5f92-5722-4c05-a7ee-e6bff8c3f8a4",
   "metadata": {},
   "source": [
    "Необработанный текст, векторизация 0-1: 0.85 \n",
    "\n",
    "Необработанный текст, векторизация 0-n: 0.847\n",
    "\n",
    "Необработанный текст, векторизация tf-idf: 0.844\n",
    "\n",
    "##\n",
    "Стеммированный текст, векторизация 0-1: 0.871\n",
    "\n",
    "Стеммированный текст, векторизация 0-n: 0.853\n",
    "\n",
    "Стеммированный текст, векторизация tf-idf: 0.871\n",
    "\n",
    "##\n",
    "Лемматизированный текст, векторизация 0-1: 0.871\n",
    "\n",
    "Лемматизированный текст, векторизация 0-n: 0.859\n",
    "\n",
    "Лемматизированный текст, векторизация tf-idf: 0.871"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
