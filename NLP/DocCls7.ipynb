{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "444aab35-0739-4650-b45b-e7104575b848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "from gensim.models import TfidfModel\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "newsgroups_train = fetch_20newsgroups(subset='all',\n",
    "                                      categories=['alt.atheism',\n",
    "                                                  # 'comp.graphics',\n",
    "                                                  # 'comp.os.ms-windows.misc',\n",
    "                                                  'comp.sys.ibm.pc.hardware',\n",
    "                                                  # 'comp.sys.mac.hardware',\n",
    "                                                  # 'comp.windows.x',\n",
    "                                                  'misc.forsale',\n",
    "                                                  'rec.autos',\n",
    "                                                  # 'rec.motorcycles',\n",
    "                                                  'rec.sport.baseball'],\n",
    "                                      remove=(\"header\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2934011b-c89c-4877-a40d-9ed3f0d9dde8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(x):\n",
    "    return train_test_split(x, newsgroups_train.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0ea3fa0-5d67-4599-8989-67b242dacd42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res(typename, dataset, solver=\"adam\",\n",
    "            hidden_layer_sizes=(10, 10),\n",
    "            activation=\"tanh\", learning_rate=\"constant\", max_iter=1000):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = split_data(dataset)\n",
    "\n",
    "    clf = MLPClassifier(random_state=42,\n",
    "                        solver=solver,\n",
    "                        hidden_layer_sizes=hidden_layer_sizes,\n",
    "                        max_iter=max_iter,\n",
    "                        learning_rate=learning_rate,\n",
    "                        activation=activation)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    acc_test = f1_score(y_true=y_test, y_pred=clf.predict(x_test), average=\"micro\")\n",
    "\n",
    "    if typename != \"TFIDF\":\n",
    "        print(f\"    {typename}:     {round(acc_test, 3)}\")\n",
    "    else:\n",
    "        print(f\"    {typename}:   {round(acc_test, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d192570c-b662-44a6-b061-a161d8df39b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_reg_exp = r'[-+]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][-+]?\\d+)?'\n",
    "special_sym = [\"(\", \")\", \":\", \"@\", \"?\", \",\", \"|\", \">\", \"<\", \"]\", \"\\'\", \"{\", \"/\", \"^\"\n",
    "               \"[\", \".\", \"``\", \"\\'\\'\", \"--\", \"!\", \"-\", \"*\", \"..\", \"$\", \"}\", \"#\", \"=\"]\n",
    "stop_words = stopwords.words('english') + special_sym\n",
    "\n",
    "\n",
    "def delete_stopword_and_lemmatize(listw):\n",
    "    res = []\n",
    "    for word in listw:\n",
    "        word = lemmatizer.lemmatize(word.lower())\n",
    "        if word not in stop_words and re.fullmatch(num_reg_exp, word) is None\\\n",
    "            and not any(sym in word for sym in special_sym):\n",
    "            res += [word]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4166c7-00e4-4a98-bd12-392e86cce8d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bow_var(bow, dictn):\n",
    "    res = []\n",
    "    for i in range(len(bow)):\n",
    "        doc = [0 for j in range(len(dictn))]\n",
    "        for val in bow[i]:\n",
    "            doc[val[0]] = val[1]\n",
    "\n",
    "        res += [doc]\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_tfidf_var(tfidf, dictn):\n",
    "    res = []\n",
    "    for i in range(len(tfidf)):\n",
    "        doc = [0 for j in range(len(dictn))]\n",
    "        for val in tfidf[i]:\n",
    "            doc[val[0]] = val[1]\n",
    "\n",
    "        res += [doc]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb50e6dd-1acc-408a-9899-dfeaf50787a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lsi(corpus, dictn):\n",
    "    lsi_model = models.LsiModel(corpus=corpus, num_topics=20, id2word=dictn)\n",
    "    lsi_res = []\n",
    "    for i in range(len(corpus)):\n",
    "        lsi_res += [[val[1] for val in lsi_model[corpus[i]]]]\n",
    "    return lsi_res\n",
    "\n",
    "\n",
    "def get_lda(corpus, dictn, alpha, bbeta):\n",
    "    lda_model = models.LdaModel(corpus=corpus, num_topics=20, id2word=dictn, passes=10, alpha=alpha, eta=bbeta)\n",
    "    lda_res = []\n",
    "    for i in range(len(corpus)):\n",
    "        lda_res += [[val[1] for val in lda_model.get_document_topics(corpus[i], minimum_probability=0.0)]]\n",
    "    return lda_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da72f83-0b30-4444-b6b7-15c1965f9401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenize_data = [delete_stopword_and_lemmatize(nltk.word_tokenize(newsgroups_train.data[i]))\n",
    "                 for i in range(len(newsgroups_train.data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15eb9a6-76f8-42dc-8b57-7e9b928af2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictn = corpora.Dictionary(tokenize_data)\n",
    "dictn.filter_extremes(keep_n=1000)\n",
    "\n",
    "bow = [dictn.doc2bow(doc) for doc in tokenize_data]\n",
    "\n",
    "model = TfidfModel(bow)\n",
    "tfidf = [model[doc] for doc in bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1330e1d8-a840-49cf-b30b-71b4ae7cabc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lsi = get_lsi(tfidf, dictn)\n",
    "lda = get_lda(bow, dictn, 'symmetric', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e402cd9-b8ca-44cb-be47-6944fe9e69f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed = [get_bow_var(bow, dictn), get_tfidf_var(tfidf, dictn), lsi, lda]\n",
    "names = [\"BoW\", \"TFIDF\", \"LSI\", \"LDA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8da4b0b1-2337-450d-be12-df241e7cfd72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier (10,):\n",
      "    BoW:     0.909\n",
      "    TFIDF:   0.914\n",
      "    LSI:     0.932\n",
      "    LDA:     0.887\n",
      "--------------------------------\n",
      "MLPClassifier (30,):\n",
      "    BoW:     0.914\n",
      "    TFIDF:   0.91\n",
      "    LSI:     0.939\n",
      "    LDA:     0.887\n",
      "--------------------------------\n",
      "MLPClassifier (100,):\n",
      "    BoW:     0.91\n",
      "    TFIDF:   0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LSI:     0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LDA:     0.885\n",
      "--------------------------------\n",
      "MLPClassifier (10, 10):\n",
      "    BoW:     0.901\n",
      "    TFIDF:   0.908\n",
      "    LSI:     0.937\n",
      "    LDA:     0.888\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "vec_hidden_layer_sizes = [(10, ), (30, ), (100, ), (10, 10)]\n",
    "\n",
    "for hidden_layer in vec_hidden_layer_sizes:\n",
    "    print(f\"MLPClassifier {hidden_layer}:\")\n",
    "    for i in range(len(embed)):\n",
    "        get_res(f\"{names[i]}\", embed[i], hidden_layer_sizes=hidden_layer)\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97ff5254-ee34-426a-a64d-a195b967158e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier identity:\n",
      "    BoW:     0.899\n",
      "    TFIDF:   0.907\n",
      "    LSI:     0.93\n",
      "    LDA:     0.886\n",
      "--------------------------------\n",
      "MLPClassifier logistic:\n",
      "    BoW:     0.906\n",
      "    TFIDF:   0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LSI:     0.936\n",
      "    LDA:     0.887\n",
      "--------------------------------\n",
      "MLPClassifier tanh:\n",
      "    BoW:     0.91\n",
      "    TFIDF:   0.908\n",
      "    LSI:     0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LDA:     0.89\n",
      "--------------------------------\n",
      "MLPClassifier relu:\n",
      "    BoW:     0.901\n",
      "    TFIDF:   0.908\n",
      "    LSI:     0.937\n",
      "    LDA:     0.888\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "vec_activation = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "\n",
    "for elem in vec_activation:\n",
    "    print(f\"MLPClassifier {elem}:\")\n",
    "    for i in range(len(embed)):\n",
    "        get_res(f\"{names[i]}\", embed[i], activation=elem)\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6390c4d1-4ab7-460a-a70b-330c5877d562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier adam:\n",
      "    BoW:     0.91\n",
      "    TFIDF:   0.908\n",
      "    LSI:     0.934\n",
      "    LDA:     0.89\n",
      "--------------------------------\n",
      "MLPClassifier sgd:\n",
      "    BoW:     0.923\n",
      "    TFIDF:   0.925\n",
      "    LSI:     0.923\n",
      "    LDA:     0.888\n",
      "--------------------------------\n",
      "MLPClassifier lbfgs:\n",
      "    BoW:     0.886\n",
      "    TFIDF:   0.916\n",
      "    LSI:     0.909\n",
      "    LDA:     0.852\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "vec_solver = [\"adam\", \"sgd\", \"lbfgs\"]\n",
    "\n",
    "for elem in vec_solver:\n",
    "    print(f\"MLPClassifier {elem}:\")\n",
    "    for i in range(len(embed)):\n",
    "        get_res(f\"{names[i]}\", embed[i], solver=elem)\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b2f5650-b971-4782-9294-b5d2b71272df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier constant:\n",
      "    BoW:     0.93\n",
      "    TFIDF:   0.883\n",
      "    LSI:     0.834\n",
      "    LDA:     0.87\n",
      "--------------------------------\n",
      "MLPClassifier invscaling:\n",
      "    BoW:     0.303\n",
      "    TFIDF:   0.236\n",
      "    LSI:     0.231\n",
      "    LDA:     0.231\n",
      "--------------------------------\n",
      "MLPClassifier adaptive:\n",
      "    BoW:     0.93\n",
      "    TFIDF:   0.883\n",
      "    LSI:     0.834\n",
      "    LDA:     0.87\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "vec_learning_rate = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "\n",
    "for elem in vec_learning_rate:\n",
    "    print(f\"MLPClassifier {elem}:\")\n",
    "    for i in range(len(embed)):\n",
    "        get_res(f\"{names[i]}\", embed[i], learning_rate=elem, solver=\"sgd\", max_iter=200)\n",
    "    print(\"--------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
