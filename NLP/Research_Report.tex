\documentclass[12pt, a4paper]{article}
\usepackage[english, russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm,bindingoffset=0mm]{geometry}
\usepackage{titlesec}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[pdftex]{graphicx}
\usepackage{dsfont}
\usepackage{comment}
\usepackage[unicode, pdftex]{hyperref}
\usepackage{fancyhdr}
\usepackage{colortbl}

\graphicspath{{C:/Users/user/Desktop/Kalman_foto}}
\newtheorem{theorem}{$\quad$ Теорема}
\setlength{\parindent}{5mm}
\linespread{1.4}


\begin{document}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}

\begin{center}
САНКТ-ПЕТЕРБУРГСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ\\
Направление: 01.03.02 Прикладная математика и информатика \\
Кафедра технологии программирования \\

\vspace*{2cm}
\large \textbf{ОТЧЕТ О НАУЧНО-ИССЛЕДОВАТЕЛЬСКОЙ РАБОТЕ}
\end{center}
\vspace*{2cm}

\hspace*{0.5cm}
Tема задания: Исследование алгоритмов лемматизации
\vspace*{1cm}

\hspace*{0.5cm}
Выполнил: Смирнов Алексей Артёмович, группа 21.Б02-пу 
\vspace*{1cm}

\hspace*{0.5cm}
Руководитель научно- \\
\hspace*{1cm} исследовательской работы: Блеканов Иван Станиславович, кандидат технических \\\hspace*{1cm} наук, доцент, заведующий кафедрой технологии программирования
 
 
\vspace*{10cm}
\begin{center}
САНКТ-ПЕТЕРБУРГ \\
2023
\end{center}

\newpage

\renewcommand{\contentsname}{\begin{center}Содержание\end{center}}
\tableofcontents

\newpage

\fancyfoot[C]{\thepage}

\section{Введение}
\quad Данная работа посвящена изучению технологии Natural Language Processing(NLP) - одной из важнейших отраслей машинного обучения, дающую возможность обработки и создания информации на естественном языке. Мы рассмотрим лишь часть NLP, называемую лемматизацией, получим численную оценку нескольких популярных алгоритмов на реальных данных, что позволит оценить данную задачу со всех сторон.

Лемматизация - процесс приведения словоформы к лемме, то есть к её нормальной форме. В русском языке при построении текста используются различные формы слова в зависимости от контекста, но в большинстве случаев идею текста можно понять заменив все слова на их нормальные формы, тем самым можно облегчить задачу компьютеру, уменьшив количество вариаций входных данных. Например все формы: \text{'ездил', 'ездила', 'ездили'} после лемматизации становятся равными \text{'ездить'}. Конечно, хоть лемматизация упрощает работу с текстом, после ее выполнения мы теряем часть информации заложенной изначально, но для задач классификации и кластеризации документов необязательно знать всю информацию заложенную в них, достаточно различать лишь те признаки, которые позволяют определять объекты одного класса.

\subsection{Актуальность работы}
\quad Исследование различных алгоритмов лемматизации может помочь наиболее эффективно подбирать соответвующие методы в зависимости от конкретных задач на основе знания их преймуществ и недостатков, а также понимать наиболее важные проблемы и их решения в данной области. Усовершенствование технологии NLP может привести к переходу к Natural Language Understanding(NLU), сделав возможным обработку не самого языка, а образов, которые закладывает человек при написании текста. Также ныне реализованные языковые модели, способные общаться с человеком, поддерживая разговоры на определенную тему, показывают практическую применимость рассматриваемых методов в различных сферах деятельности человека.

\subsection{Цель и задачи работы}
\quad Цель данной работы в описании и практической оценке популярных алгоритмов лемматизации для русского языка, сравнении их преймуществ и недостатков, а также в рассмотрении возможностей их усовершенствования с примерами фреймворков, использующихся на практике.

\section{Различные метрики символьных последовательностей}
\quad Основная идея ввода различных метрических хактеристик состоит в том, что мы хотим представить слово как элемент некоторого метрического пространства. Если мы будем знать все нормальные формы всех слов, то есть иметь словарь языка, то, в предположении, что словоформа не сильно отличается от своей нормальной формы по введеной метрике, мы сможем найти ближайший элемент из словаря, который и будет являться леммой.

Стоит отметить, что в современных алгоритмах данные метрики используются лишь как один из этапов приведения слова к лемме. Рассмотрим несколько примеров таких метрик.

\subsection{Расстояние Левенштейна}
\quad Расстояние Левенштейна - метрика, определяющая расстояние между символьными последовательностями по минимальному количеству односимвольных операций: \textbf{вставок}, \textbf{удалений} и \textbf{замены}, необходимых для приведения одной последовательности к другой. 

Для определения минимального количества операций определенных выше, необходимо вычислить значение $D(m, n)$, где $m$ - длина слова $\:W_1$, $n$ - длина слова $\:W_2$. Значение $\;D(m, n)\;$ можно вычислить по следующей реккурентной формуле:

$$
\label{2.1}
D(i, j) = 
\begin{cases} 
\max(i, j), \quad \quad \quad \quad \quad \; \; \min(i, j) = 0  \\
\min( \quad \quad \quad  \quad  \quad \quad \quad \quad \text{иначе}\\
\quad D(i, j - 1) + 1, \\
\quad D(i - 1, j) + 1, \\
\quad D(i - 1, j - 1) + (W_1[i] \: \neq \: W_2[j]) \\
\quad )
\end{cases}
\eqno(2.1)
$$

$$
(W_1[i] \: \neq \: W_2 [j]) = 
\begin{cases} 
1, \quad \text{если i-тый символ} \;\; W_1 \;\; \text{неравен j-тому символу}\;\; W_2 \\
0  \quad \; \text{иначе}
\end{cases}
$$

Из вида формулы $(\ref{2.1})$ можно получить оценку сложности по времени и памяти для  алгоритма, который принимал бы на вход слово длины $n$ и по известному словарю лемм языка, с количеством слов -  $N$, выдавал ближайшую лемму по расстоянию Левенштейна, которую и будем считать нормальной формой данного слова. Значение оценки по времени есть $O(Nna)$, где $a$ - средняя длина слова в словаре, по памяти - $O(na)$, которую можно сократить до $O(\min\{n, a\})$, так как нас не интересует способ приведения строк к равенству.

Сразу можно увидеть серьезный идейный недостаток данной метрики для задачи лемматизации, а именно то, что расстояние между короткими несовпадающими словами может быть довольно мало, из-за чего результат лемматизации отдельных коротких слов может быть сильно ошибочным, искажающим суть текста.

\subsection{Расстояние Джаро}
\quad Расстояние Джаро - метрика, определяющая расстояние между символьными последовательностями по их схожести. В отличии от расстояния Левенштейна, чем больше значение метрики, тем более строки похожи друг на друга, так как метрика основана на совпадающих символах.

Расстояние Джаро $\:d_j\:$ между двумя словами $\:W_1\;$ и $\:W_2\;$ определяется по следующей формуле:

$$
\label{2.2}
d_j = 
\begin{cases} 
0, &m = 0\\
\frac{1}{3}\left(\frac{m}{n_1} + \frac{m}{n_2} + \frac{m - t}{m}\right) \quad &\text{иначе}
\end{cases},
\eqno(2.2)
$$

где $n_1$, $n_2$ - длины слов $\:W_1\;$ и $\:W_2\;$, $m$ - количество совпадающих символов, расстояние между местами которых не превосходит $\lfloor \max\{n_1, n_2\}\,/\,2 \rfloor - 1$, $t$ - количество транспозиций, которое равно числу неупорядоченных пар совпадающих символов, чьи номера мест в соответвующих словах различны.

Из формулы $(\ref{2.2})$ получим оценки алгоритма описанного выше, где вместо расстояния Левенштейна будем использовать расстояние Джаро. Сложность по времени сопоставима с использованием расстояния Левенштейна, которая равна $O(Nna)$. Сложность по памяти равна $O(1)$.

Аналогично расстоянию Левенштейна, данная метрика может плохо справляться со словами малой длины, так как из формулы видно, что ценность совпадающего символа, для данной метрики, зависит от длин слов, из-за чего короткие слова могут иметь довольно большое значение $d_j$.

Также один из недостатков расстояния Джаро состоит в том, что слова состоящие из один и тех же символов на разных местах также могут иметь довольно большое значение $d_j \leq 2/3$, так как высокое значение $t$ штрафует не вычитанием из уже имеющегося, а отсутствием прибавки, что также может негативно сказаться на нашей метрической оценке.

\subsection{Расстояние Джаро-Винклера}
\quad Расстояние Джаро-Винклера - псевдометрика, являющаяся обобщением рассмотренного ранее расстояния Джаро, основанная на добавке в виде префиксного бонуса для префиксносовпадающих символьных последовательностей. Расстояние Джаро-Винклера $d_{jw}$ между двумя словами $\:W_1\;$ и $\:W_2\;$ определяется по следующей формуле:

$$
\label{2.3}
d_{jw} = 
\begin{cases} 
d_j, &d_j < b\\
d_j + lp(1-d_j) &d_j \geq b
\end{cases},
\eqno(2.3)
$$

где $l$ - длина общего префикса слов $\:W_1\;$ и $\:W_2\;$, $p$ - коэффициент масштабирования, $b$ - порог усиления, произведение $lp \leq 1$. Преймущество расстояния Джаро-Винклера над предыдущими метриками в том, что оно является трех-параметрическим семейством, что позволяет подбирать соответвующие параметры из практических нужд. Например в стандартной вариации принимают: $p=0.1$, $l=\min\{l, 4\}$, $b=0.7$.

Из формулы $(\ref{2.3})$ очевидны оценки сложности по времени - $O(Nna)$, и по памяти - $O(1)$.

Префиксная добавка $lp(1-d_j)$ направлена на устранение недостатков расстояния Джаро, описанных выше, так как, благодаря подсчету значения длины общего префикса $l$, короткие совпадающие слова получают большой бонус к занчению метрики из-за того, что совпадающий префикс может быть сравним с длиной всего слова. Проблема слов из совпадающих символов на одинаковых местах также частично решается параметром $l$, так как эти слова не получают префиксную добавку, хотя она, также как и параметр количества транспозиций $t$, не вычитает величину из уже имеющегося значения при малом $l$, а лишь не дает прибавку, что не защищает от потенциально высокого значения метрики в $2/3$.

Недостаток расстояния Джаро-Винклера состоит в том, что неправильно подобранный параметр $b$ могут ухудшить результаты по сравнению с расстоянием Джаро на определенных вариантах входных данных, так как большую добавку могут получить неверные варианты нормальной формы, например если нормальная форма слова имеет отличный префикс от тестируемой формы.

\subsection{Результаты практического тестирования метрик}
\quad Тестирование приведенных выше метрик будем на детасете $\hyperlink{r1}{[1]}$ 








\section{Ссылки}

\hypertarget{r1} $[1]$ \href{https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/master/ru_syntagrus-ud-dev.conllu}{\textcolor{blue}{Используемый датасет для практического тестирования алгоритма}}

\end{document}