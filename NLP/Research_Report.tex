\documentclass[12pt, a4paper]{article}
\usepackage[english, russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm,bindingoffset=0mm]{geometry}
\usepackage{titlesec}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[pdftex]{graphicx}
\usepackage{dsfont}
\usepackage{comment}
\usepackage[unicode, pdftex]{hyperref}
\usepackage{fancyhdr}

\graphicspath{{C:/Users/user/Desktop/Kalman_foto}}
\newtheorem{theorem}{$\quad$ Теорема}
\setlength{\parindent}{5mm}
\linespread{1.4}


\begin{document}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}

\begin{center}
САНКТ-ПЕТЕРБУРГСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ\\
Направление: 01.03.02 Прикладная математика и информатика \\
Кафедра технологии программирования \\

\vspace*{2cm}
\large \textbf{ОТЧЕТ О НАУЧНО-ИССЛЕДОВАТЕЛЬСКОЙ РАБОТЕ}
\end{center}
\vspace*{2cm}

\hspace*{0.5cm}
Tема задания: Исследование алгоритмов лемматизации
\vspace*{1cm}

\hspace*{0.5cm}
Выполнил: Смирнов Алексей Артёмович, группа 21.Б02-пу 
\vspace*{1cm}

\hspace*{0.5cm}
Руководитель научно- \\
\hspace*{1cm} исследовательской работы: Блеканов Иван Станиславович, кандидат технических \\\hspace*{1cm} наук, доцент, заведующий кафедрой технологии программирования
 
 
\vspace*{10cm}
\begin{center}
САНКТ-ПЕТЕРБУРГ \\
2023
\end{center}

\newpage

\renewcommand{\contentsname}{\begin{center}Содержание\end{center}}
\tableofcontents

\newpage

\fancyfoot[C]{\thepage}

\section{Введение}
\quad Данная работа посвящена изучению технологии Natural Language Processing(NLP) - одной из важнейших отраслей машинного обучения, дающую возможность обработки и создания информации на естественном языке. Мы рассмотрим лишь часть NLP, называемую лемматизацией, получим численную оценку нескольких популярных алгоритмов на реальных данных, что позволит оценить данную задачу со всех сторон.

Лемматизация - процесс приведения словоформы к лемме, то есть к её нормальной форме. В русском языке при построении текста используются различные формы слова в зависимости от контекста, но в большинстве случаев идею текста можно понять заменив все слова на их нормальные формы, тем самым можно облегчить задачу компьютеру, уменьшив количество вариаций входных данных. Например все формы: \text{'ездил', 'ездила', 'ездили'} после лемматизации становятся равными \text{'ездить'}. Конечно, хоть лемматизация упрощает работу с текстом, после ее выполнения мы теряем часть информации заложенной изначально, но для задач классификации и кластеризации документов необязательно знать всю информацию заложенную в них, достаточно различать лишь те признаки, которые позволяют определять объекты одного класса.

\subsection{Актуальность работы}
\quad На фоне развития языковых моделей способных общаться с человеком, поддерживая разговоры на определенную тему, сложно переоценить актуальность методов обработки естественного языка. Их дальнейшее развитие может привести к переходу от NLP к Natural Language Understanding(NLU), сделав возможным обработку не самого языка, а образов, которые закладывает человек при написании текста.

\subsection{Цель и задачи работы}
\quad Цель данной работы в описании и объективной оценке популярных алгоритмов лемматизации для русского языка, перечислении их преймуществ и недостатков. Также будут рассматриваться возможности их усовершенствования и примеры использования на практике.

\section{Различные метрические характеристики символьных последовательностей}
\quad Основная идея ввода различных метрических хактеристик состоит в том, что мы хотим представить слово как элемент некоторого метрического пространства. Если мы будем знать все нормальные формы всех слов, то есть иметь словарь языка, то, в предположении, что словоформа не сильно отличается от своей нормальной формы по введеной метрике, мы сможем найти ближайший элемент из словаря, который и будет являться леммой.

Стоит отметить, что в современных алгоритмах данные метрики используются лишь как один из этапов приведения слова к лемме. Рассмотрим несколько примеров таких метрик.

\subsection{Расстояние Левенштейна}
\quad Расстояние Левенштейна - метрика, определяющая расстояние между символьными последовательностями по минимальному количеству односимвольных операций: \textbf{вставок}, \textbf{удалений} и \textbf{замены}, необходимых для приведения одной последовательности к другой. 

Для определения минимального количества операций определенных выше, необходимо вычислить значение $D(m, n)$, где $m$ - длина слова $\:W_1$, $n$ - длина слова $\:W_2$. Значение $\;D(m, n)\;$ можно вычислить по следующей реккурентной формуле:

$$
\label{2.1}
D(i, j) = 
\begin{cases} 
\max(i, j), \quad \quad \quad \quad \quad \; \; \min(i, j) = 0  \\
\min( \quad \quad \quad  \quad  \quad \quad \quad \quad \text{иначе}\\
\quad D(i, j - 1) + 1, \\
\quad D(i - 1, j) + 1, \\
\quad D(i - 1, j - 1) + (W_1[i] \: \neq \: W_2[j]) \\
\quad )
\end{cases}
\eqno(2.1)
$$

$$
(W_1[i] \: \neq \: W_2 [j]) = 
\begin{cases} 
1, \quad \text{если i-тый символ} \;\; W_1 \;\; \text{неравен j-тому символу}\;\; W_2 \\
0  \quad \; \text{иначе}
\end{cases}
$$

Из вида формулы $(\ref{2.1})$ можно получить оценку сложности по времени и памяти для  алгоритма, который принимал бы на вход слово длины $n$ и по известному словарю лемм языка, с количеством слов -  $N$, выдавал ближайшую лемму по расстоянию Левенштейна, которую и будем считать нормальной формой данного слова. Значение оценки по времени есть $O(Nna)$, где $a$ - средняя длина слова в словаре, по памяти - $O(na)$, которую можно сократить до $O(\min\{n, a\})$, так как нас не интересует способ приведения строк к равенству.

Сразу можно увидеть серьезный идейный недостаток данной метрики для задачи лемматизации, а именно то, что расстояние между короткими несовпадающими словами может быть довольно мало, из-за чего результат лемматизации отдельных коротких слов может быть сильно ошибочным, искажающим суть текста.

\subsection{Расстояние Джаро}
\quad Расстояние Джаро - метрика, определяющая расстояние между символьными последовательностями по их схожести. В отличии от расстояния Левенштейна, чем больше значение метрики, тем более строки похожи друг на друга, так как метрика основана на совпадающих символах.

Расстояние Джаро $\:d_j\:$ между двумя словами $\:W_1\;$ и $\:W_2\;$ определяется по следующей формуле:

$$
\label{2.2}
d_j = 
\begin{cases} 
0, &m = 0\\
\frac{1}{3}\left(\frac{m}{n_1} + \frac{m}{n_2} + \frac{m - t}{m}\right) \quad &\text{иначе}
\end{cases},
\eqno(2.2)
$$

где $n_1$, $n_2$ - длины слов $\:W_1\;$ и $\:W_2\;$, $m$ - количество совпадающих символов, расстояние между местами которых не превосходит $\lfloor \max\{n_1, n_2\}\,/\,2 \rfloor - 1$, $t$ - количество транспозиций, которое равно числу неупорядоченных пар совпадающих символов, чьи номера мест в соответвующих словах различны.

Из формулы $(\ref{2.2})$ получим оценки алгоритма описанного выше, где вместо расстояния Левенштейна будем использовать расстояние Джаро. 






\end{document}