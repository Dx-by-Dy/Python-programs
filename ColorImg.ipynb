{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95641b0-2a13-47a0-875a-014cca6e02a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e8c882-d30c-4387-80b8-027203e322de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preproc_data():\n",
    "    targets, samples = [], []\n",
    "\n",
    "    with ZipFile(\"fotoarc.zip\", \"r\") as zip_data:\n",
    "        cnt_file = len(zip_data.namelist())\n",
    "        with tqdm(total=cnt_file, position=0, leave=True) as pbar:\n",
    "            for fileidx in range(cnt_file):\n",
    "\n",
    "                file = zip_data.filelist[fileidx]\n",
    "                name = file.filename\n",
    "                zip_data.extract(name, path=\"fotoarc/\")\n",
    "\n",
    "                img = cv2.imread('fotoarc/' + name)\n",
    "                img = cv2.resize(img, (256, 256))\n",
    "\n",
    "                yuv = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "                samples += [yuv[:, :, 0]]\n",
    "                targets += [yuv[:, :, 1:]]\n",
    "\n",
    "                os.remove(\"fotoarc/\" + name)\n",
    "\n",
    "                pbar.set_description(f\"Files: {fileidx+1}/{cnt_file}\")\n",
    "                pbar.update()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(samples,\n",
    "                                                        targets,\n",
    "                                                        test_size=0.2,\n",
    "                                                        shuffle=True,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = torch.Tensor(np.array(x_train)), \\\n",
    "        torch.Tensor(np.array(x_test)), \\\n",
    "        torch.Tensor(np.array(y_train)), \\\n",
    "        torch.Tensor(np.array(y_test))\n",
    "\n",
    "    return TensorDataset(x_train, y_train), TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c899ff5a-1171-49de-b92f-0c30482b6cad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_img(tensor_L, tensor_UV):\n",
    "    img = np.uint8(torch.cat((tensor_L.view(256, 256, 1), tensor_UV), dim=2))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_LUV2RGB)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad39478-d119-4275-af1a-0cca1607c1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files: 7129/7129: 100%|████████████████████████████████████████████████████████████| 7129/7129 [01:59<00:00, 59.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = preproc_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f43f77b-b3f5-4848-b3f4-490e0caaa54f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader, test_loader = DataLoader(train_dataset, batch_size), DataLoader(test_dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c651520-3bcc-45ee-bd30-5aed22387693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_img(train_dataset[0][0], train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "811f37f4-4d7c-4820-a8bc-64b45f036a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_CI(nn.Module):\n",
    "    def __init__(self, parameters={}):\n",
    "        super().__init__()\n",
    "\n",
    "        # ----------------------------------------- model -------------------------------------------\n",
    "        # 256x256x1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, stride=2, padding=2)\n",
    "        # 128x128x64\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        # 64x64x128\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
    "        # 32x32x512\n",
    "        self.conv4 = nn.Conv2d(in_channels=512, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        # 32x32x128\n",
    "        # resize 256x256x2\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        self.name = \"ColorImg_1_0\"\n",
    "        self.modules = [\"conv1\", \"conv2\", \"conv3\", \"conv4\"]\n",
    "\n",
    "        self.load_self(parameters)\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def init_weigth(self):\n",
    "        for module in self.modules:\n",
    "            nn.init.xavier_uniform_(getattr(self, module).weight)\n",
    "\n",
    "    def testing(self, test_dataloader):\n",
    "        len_test_data = len(test_dataloader)\n",
    "\n",
    "        with tqdm(total=len_test_data, position=0, leave=True) as pbar:\n",
    "\n",
    "            self.eval()\n",
    "            running_loss = 0\n",
    "            num_test = 1\n",
    "\n",
    "            for test in test_dataloader:\n",
    "                x_data = test[0].view(test[0].shape[0], 1, 256, 256).to(self.device)\n",
    "                y_data = test[1].to(self.device)\n",
    "\n",
    "                y_pred = self(x_data)\n",
    "                loss = self.criterion(y_pred, y_data)\n",
    "\n",
    "                loss.backward()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                pbar.set_description(f\"Test: {num_test}/{len_test_data}, Loss: {running_loss}\")\n",
    "                pbar.update()\n",
    "\n",
    "                num_test += 1\n",
    "\n",
    "        self.history_test_loss.update({self.epochs_train: running_loss})\n",
    "        self.save()\n",
    "\n",
    "    def fit(self, train_dataloader, epochs):\n",
    "        len_train_data = len(train_dataloader)\n",
    "\n",
    "        with tqdm(total=epochs * len_train_data, position=0, leave=True) as pbar:\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                self.train()\n",
    "                running_loss = 0\n",
    "                num_batch = 1\n",
    "\n",
    "                for batch in train_dataloader:\n",
    "                    x_data = batch[0].view(batch[0].shape[0], 1, 256, 256).to(self.device)\n",
    "                    y_data = batch[1].to(self.device)\n",
    "\n",
    "                    y_pred = self(x_data)\n",
    "                    loss = self.criterion(y_pred, y_data)\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                    pbar.set_description(f\"Epoch: {self.epochs_train + 1}/{self.epochs_train + epochs - epoch}, Batch: {num_batch}/{len_train_data}, Loss: {running_loss}\")\n",
    "                    pbar.update()\n",
    "\n",
    "                    num_batch += 1\n",
    "\n",
    "                self.epochs_train += 1\n",
    "                self.history_train_loss.update({self.epochs_train: running_loss})\n",
    "                self.save()\n",
    "\n",
    "        self.pretrained = True\n",
    "        self.save()\n",
    "\n",
    "    def load_self(self, parameters):\n",
    "        try:\n",
    "            checkpoint = torch.load(f\"{self.name}.pth\")\n",
    "\n",
    "            self.pretrained = True\n",
    "            self.learning_rate = checkpoint[\"learning_rate\"]\n",
    "            self.load_state_dict(checkpoint['load_state_dict'])\n",
    "            self.optimizer = checkpoint['optimizer']\n",
    "            self.epochs_train = checkpoint[\"epochs_train\"]\n",
    "            self.history_train_loss = checkpoint[\"history_train_loss\"]\n",
    "            self.history_test_loss = checkpoint[\"history_test_loss\"]\n",
    "            self.device = checkpoint[\"device\"]\n",
    "            self.criterion = checkpoint[\"criterion\"]\n",
    "\n",
    "        except FileNotFoundError:\n",
    "\n",
    "            self.pretrained = False\n",
    "            self.learning_rate = parameters[\"learning_rate\"]\n",
    "\n",
    "            self.init_weigth()\n",
    "            self.optimizer = parameters[\"optimizer\"](self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "            self.epochs_train = 0\n",
    "            self.history_train_loss = {}\n",
    "            self.history_test_loss = {}\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            self.criterion = parameters[\"criterion\"]\n",
    "\n",
    "    def save(self):\n",
    "        checkpoint = {\"load_state_dict\": self.state_dict(),\n",
    "                      \"learning_rate\": self.learning_rate,\n",
    "                      \"optimizer\": self.optimizer,\n",
    "                      \"epochs_train\": self.epochs_train,\n",
    "                      \"history_train_loss\": self.history_train_loss,\n",
    "                      \"history_test_loss\": self.history_test_loss,\n",
    "                      \"device\": self.device,\n",
    "                      \"criterion\": self.criterion}\n",
    "\n",
    "        torch.save(checkpoint, f\"{self.name}.pth\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(x.shape[0], 256, 256, 2)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6dfb283-d39a-40d2-a96e-7be59d615f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CNN_CI(parameters={\"learning_rate\": 0.005,\n",
    "                           \"optimizer\": Adam,\n",
    "                           \"criterion\": nn.CrossEntropyLoss()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e3bc4bb-097d-4e70-85eb-09183e0be07f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.005\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc63f0c-c8b8-4381-a47b-21b2ff391ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/3, Batch: 179/179, Loss: 30305198.9375: 100%|███████████████████████████████| 537/537 [03:54<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_loader, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb8bf86a-e39f-41a6-aa64-2ba567d8b856",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 38339434.875, 2: 30305240.203125, 3: 30305198.9375}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b14e268e-d594-4574-a0a2-946291cc2720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 1426/1426, Loss: 241902751.9375: 100%|███████████████████████████████████████| 1426/1426 [00:30<00:00, 46.82it/s]\n"
     ]
    }
   ],
   "source": [
    "model.testing(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bde50ebd-ca0c-40b0-8949-b4bf9b0f8203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 241902751.9375}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e0fcf76-5156-4cb7-b800-d078d6c36a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CNN_CI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aac3aa55-c28e-4e36-a574-94fc55703864",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 38339434.875, 2: 30305240.203125, 3: 30305198.9375}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fb13181-d099-4ef8-a8d3-2aca865b7ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5, Batch: 179/179, Loss: 30305146.015625: 100%|█████████████████████████████| 179/179 [01:13<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79f6f086-0fd7-4f70-b7fb-cc9cc8a75edf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 38339434.875,\n",
       " 2: 30305240.203125,\n",
       " 3: 30305198.9375,\n",
       " 4: 30305146.015625,\n",
       " 5: 30305146.015625}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history_train_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
